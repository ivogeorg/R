?Classes
?Methods
?colSums
?getMethod
require(datasets)
data(mtcars)
summary(mtcars)
str(mtcars)
unique(mtcars)
sapply(mtcars, unique)
?mtcars
plot(mpg ~ as.factor(am), data = mtcars)
plot(mpg ~ as.factor(am), data = mtcars, main = "MPG vs transmission")
plot(mpg ~ as.factor(am), data = mtcars, main = "MPG vs Type of Transmission")
plot(mpg ~ as.factor(am), data = mtcars,
main = "MPG vs Transmission Type",
xlab = "Type of transmission",
ylab = "Miles per galon")
plot(mpg ~ as.factor(am), data = mtcars,
main = "MPG vs Transmission Type",
xlab = "Type of transmission",
ylab = "Miles per galon",
xaxt = "n")
?axis
plot(mpg ~ as.factor(am), data = mtcars,
main = "MPG vs Transmission Type",
xlab = "Type of transmission",
ylab = "Miles per galon",
xaxt = "n")
axis(1, at = 1:2, labels = c("Automatic", "Manual"))
fit1 <- lm(mpg ~ as.factor(am), data = mtcars)
fit1
plot(fit1)
attributes(fit1)
fit1$coefficients
fit1$residuals
mtcars
?transform
cars <- transform(mtcars, cyl = as.factor(cyl), vs = as.factor(vs), gear = as.factor(gear), am = as.factor(am), carb = as.factor(carb))
fitall <- lm(mpg ~ ., cars)
fitall
fit1
cars
carsauto <- cars[am = 0, ]
carsauto <- cars[cars$am = 0, ]
carsauto <- cars[cars$am == 0, ]
carsman <- cars[cars$am == 1, ]
?t.test
t.test(carsauto$mpg, carsman$mpg, paired = FALSE, var.equal = FALSE)
ttest <- t.test(carsauto$mpg, carsman$mpg, paired = FALSE, var.equal = FALSE)
c(ttest$statistic, ttest$p.value, ttest$conf.int)
c(ttest$statistic, p-value = ttest$p.value, ttest$conf.int)
res <- c(ttest$statistic, p-value = ttest$p.value, ttest$conf.int)
res <- c(ttest$statistic, p-value = ttest$p.value, ttest$conf.int)
res <- c(ttest$statistic, ttest$p.value, ttest$conf.int)
names(res) = c("t", "p-value", "95%-lower", "95%-upper")
res
install.packages("cummerbund")
install.packages("cummeRbund")
install.packages("bioconductor")
source("https://bioconductor.org/biocLite.R")
biocLite()
v <- c(0.3, 2.8, 5.3)
mean(v)
var1 <- sum((v-mean(v))^2)/2
var1
var(v)
down.step <- -1*sqrt(3/2)
up.step <- sqrt(2/3)
walk <- seq(1:5, NULL)
?seq
?replications
?rep  replications
?rep
walk <- rep(0, times=5)
walk
steps <- c(up.step, down.step, up.step, up.step, down.step)
steps
walk[1] <- sum(steps[1:1])
walk[2] <- sum(steps[1:2])
walk[3] <- sum(steps[1:3])
walk[4] <- sum(steps[1:4])
walk[5] <- sum(steps[1:5])
walk
plot(walk)
max(walk)
min(walk)
c1 <- matrix(c(1.1, 0.3, 0.9, 0.1), 1, 1, byrow = TRUE)
c1
c1 <- matrix(c(1.1, 0.3, 0.9, 0.1), 2, 2, byrow = TRUE)
c1
c2 <- matrix(c(0.5, 2.4, 0.6, 1.2), 2, 2, byrow = TRUE)
mean(c1)
d1 <- data.frame(c1)
d1
mean(d1)
apply(d1, mean)
apply(d1, fun=mean)
vapply(c1, mean)
?vapply
lapply(d1, mean)
sapply(d1, mean)
c1.mean <= sapply(d1, mean)
c1.mean <- sapply(d1, mean)
d2 <- data.frame(c2)
c2.mean <- sapply(d2, mean)
c2.mean
c2
c1-c1.mean
c1
c1.mean
c1-t(c1.mean)
class(c1.mean)
t(c1.mean)
?t
c1.mean <- matrix(c1.mean, 2, 1)
c1.mean
c1-c1.mean
lapply(c1, function(x) x-c1.mean)
c1
c1
c1.mean
c1[,1] <= c1[,1]-c1.mean
c1[,1] <- c1[,1]-c1.mean
c1[,2] <- c1[,2]-c1.mean
c1
c1*c1
c1.mean <- sapply(d1, mean)
c1 <- matrix(c(1.1, 0.3, 0.9, 0.1), 2, 2, byrow = TRUE)
c1.mean <- sapply(d1, mean)
c1
c1.mean
c1[1,] <- c1[1,]-c1.mean
c1[2,] <- c1[2,]-c1.mean
c1
c1*c1
c1.sq <- c1*c1
c1
c1 <- matrix(c(1.1, 0.3, 0.9, 0.1), 2, 2, byrow = TRUE)
c1
?aggregate
aggregate(c1, 1, mean)
aggregate(data.frame(c1), by=names, fun="mean")
aggregate(data.frame(c1), by=names, FUN ="mean")
sapply(c1, mean)
c1
sapply(data.frame(c1), mean)
c1.mean <- sapply(data.frame(c1), mean)
c1
c1.mean
?apply
c1
apply(c1, 1, mean)
apply(c1, 2, mean)
c1.mean <- apply(c1, 2, mean)
c2 <- matrix(c(0.5, 2.4, 0.6, 1.2), 2, 2, byrow = TRUE)
c2
c2.mean <- apply(c2, 2, mean)
c2.mean
apply(c1, 1, function(x) x-c1.mean)
c1
c1.mean
c[1,]-c1.mean
c1[1,]-c1.mean
c1
apply(c1, 1, function(x) x-c1.mean)
apply(c1, 2, mean)
apply(c1, 2, function(x) x-mean(x))
c1
apply(c1, 2, function(x) y<-x-mean(x);y^2)
apply(c1, 2, function(x) {y<-x-mean(x);y^2})
s1 <- apply(c1, 2, function(x) { y <- x-mean(x); y^2 })
s1
apply(s1, 1, sum)
apply(s1, 1, function(x) sqrt(sum(x)))
r1 <- apply(s1, 1, function(x) sqrt(sum(x)))
r1
sum(r1)
c2
s2 <- apply(c2, 2, function(x) { y <- x-mean(x); y^2 })
s2
r2 <- apply(s2, 1, function(x) sqrt(sum(x)))
r2
sum(r2)
sum(r1)+ sum(r2)
s1
s2
sum(s1)
sum(s2)
c1
apply(c1, 2, mean)
apply(c1, 2, function(x) x-mean(x))
c1[1,] - c1.mean
c1[2,] - c1.mean
s1
c2
apply(c2, 2, mean0)
apply(c2, 2, mean)
apply(c2, 2, function(x) { y <- x-mean(x); y^2 })
c2.mean
c2[1,]-c2.mean
c2[2,]-c2.mean
s2
sum(s1) + sum(s2)
[1]*2
2*(sum(s1) + sum(s2))
c1-c2
c1
c2
e <- matrix(c(1.0, 0.5, 0.5, 0.75), 2, 2, byrow = TRUE)
e
r <- matrix(c(1.0, 0, 0, 0.75), 2, 2, byrow = TRUE)
.5*(e+r)
up.step <- function(n, g) sqrt((n-g)/g)
down.step <- function(n, g) -sqrt(g/(n-g))
n <- 10000; g <- 200
up.step(n, g)
down.step(n, g)
2*33/(23*22)
M <- matrix(c(2.0, 1.0, 3.0, 0.0), 2, 2, byrow = TRUE)
M
?eigen
eigen(M)
M %*% c(4, -1)
M %*% c(-2, 3)
M %*% c(2, 1)
M %*% c(3, 0)
M %*% c(1, 1)
M %*% c(-1, 3)
M %*% c(2, 3)
?arcsin
cd <- c(0.7, 0.7, 0.14)
v.set1 <- c(0, 0, 1)
v.set2 <- c(0, 1, 0)
sum(cd^2)
cd^2
v1 <- v.set1
v2 <- v.set2
sqrt(cd^2)
sqrt(sum(cd^2))
v1^1
v1^2
sum(v1^2)
sqrt(sum(v1^2))
a1 <- arcsin(.14/sqrt(sum(cd^2)))
?arcsin
a1 <- asin(.14/sqrt(sum(cd^2)))
a1
a2 <- asin(.7/sqrt(sum(cd^2)))
c(a1, a2)
cd
sqrt(sum(cd^2))
cd^2
sum(cd^2)
asin(.7)
asin(.14)
sin(1)
sin(pi)
asin(sin(pi))
sin(0)
asin(pi)
asin(pi*.7)
asin(.7)/pi
asin(.7)*pi
acos(.14)
acos(.7)
cos(0)
sin(0)
asin(.14)
asin(.14) * 180/pi
.411*180/pi
.395*180/pi
.935*180/pi
sin(.935)
sin(.935)*.996
sqrt(sin(.935))
sin(.935)^2
.14^2
sqrt(.14)
library(caret)
library(AppliedPredictiveModeling)
?AppliedPredictiveModeling
scriptLocation()
?createDataPartition
?diagnosis
diagnosis
v <- c(1, 3, 5, 6, 7, 8)
-v
adData=data.frame(diagnosis,predictors)
2 trainIndex=createDataPartition(diagnosis,p=0.50,list=FALSE)training=adData[trainIndex,]
testing=adData[-trainIndex,]
setwd("~/git-repos/R/data-science-specialization/datasci-8-practical-machine-learning/quizzes")
Sys.time()
format(Sys.time(), '%d %B, %Y')
?format
require(caret)
require(AppliedPredictiveModeling) # package with data
data(AlzheimerDisease)
adData     <- data.frame(diagnosis, predictors)
trainIndex <- createDataPartition(diagnosis, p=0.50, list=FALSE)
training   <- adData[trainIndex,]
testing    <- adData[-trainIndex,]
head(adData)
dim(adData)
adData[,1]
trainIndex
dim(training)
dim(testing)
class(trainIndex)
dim(trainIndex)
names(trainIndex)
head(trainIndex)
require(caret)
require(AppliedPredictiveModeling)
data(concrete)
set.seed(1000) # for repeatability
inTrain  <- createDataPartition(mixtures$CompressiveStrength,p=3/4)[[1]] # returns a list
training <- mixtures[inTrain,]
testing  <- mixtures[-inTrain,]
class(inTrain)
inTrain
dim(mixtures)
class(mixtures)
names(mixtures)
lapply(mixtures, class)
sapply(mixtures, class)
class(trainIndex)
dim(trainIndex)
require(ggplot2)
require(Hmisc)
?cut2
cut2(training$Cement, g=5)
table(cut2(training$Cement, g=5))
?qplot
qplot(seq_along(training$CompressiveStrength), training$CompressiveStrength, colour=cut2(training$Cement, g=5))
require(ggplot2)
require(Hmisc)
qplot(seq_along(training$CompressiveStrength),
training$CompressiveStrength,
colour = cut2(training$Cement),
xlab = "Compressive strength",
ylab = "Samples")
require(ggplot2)
require(Hmisc)
pl <- qplot(seq_along(training$CompressiveStrength),
training$CompressiveStrength,
colour = cut2(training$Cement),
xlab = "Compressive strength",
ylab = "Samples")
pl
?guides
require(ggplot2)
require(Hmisc)
pl <- qplot(seq_along(training$CompressiveStrength),
training$CompressiveStrength,
colour = cut2(training$Cement),
xlab = "Compressive strength",
ylab = "Samples")
pl + guide_legend(title = "Cement (factorized)")
pl
require(ggplot2)
require(Hmisc)
qplot(seq_along(training$CompressiveStrength),
training$CompressiveStrength,
colour = cut2(training$Cement),
xlab = "Compressive strength",
ylab = "Samples")
require(ggplot2)
require(Hmisc)
qplot(seq_along(training$CompressiveStrength),
training$CompressiveStrength,
colour = cut2(training$Cement),
ylab = "Compressive strength",
xlab = "Samples")
require(ggplot2)
require(Hmisc)
qplot(seq_along(training$CompressiveStrength),
training$CompressiveStrength,
colour = cut2(training$Cement),
ylab = "Compressive strength",
xlab = "Samples", guide_legend(title = "Title"))
require(ggplot2)
require(Hmisc)
qplot(seq_along(training$CompressiveStrength),
training$CompressiveStrength,
colour = cut2(training$Cement),
ylab = "Compressive strength",
xlab = "Samples")                       # TODO: how to re-label the legend?
require(ggplot2)
require(Hmisc)
qplot(seq_along(training$CompressiveStrength),
training$CompressiveStrength,
colour = cut2(training$BlastFurnaceSlag),
ylab = "Compressive strength",
xlab = "Samples")                       # TODO: how to re-label the legend?
require(ggplot2)
require(Hmisc)
qplot(seq_along(training$CompressiveStrength),
training$CompressiveStrength,
colour = cut2(training$FlyAsh),
ylab = "Compressive strength",
xlab = "Samples")                       # TODO: how to re-label the legend?
require(ggplot2)
require(Hmisc)
qplot(seq_along(training$CompressiveStrength),
training$CompressiveStrength,
colour = cut2(training$Water),
ylab = "Compressive strength",
xlab = "Samples")                       # TODO: how to re-label the legend?
require(ggplot2)
require(Hmisc)
qplot(seq_along(training$CompressiveStrength),
training$CompressiveStrength,
colour = cut2(training$Superplasticizer),
ylab = "Compressive strength",
xlab = "Samples")                       # TODO: how to re-label the legend?
require(ggplot2)
require(Hmisc)
qplot(seq_along(training$CompressiveStrength),
training$CompressiveStrength,
colour = cut2(training$CoarseAggregate),
ylab = "Compressive strength",
xlab = "Samples")                       # TODO: how to re-label the legend?
require(ggplot2)
require(Hmisc)
qplot(seq_along(training$CompressiveStrength),
training$CompressiveStrength,
colour = cut2(training$FineAggregate),
ylab = "Compressive strength",
xlab = "Samples")                       # TODO: how to re-label the legend?
require(ggplot2)
require(Hmisc)
qplot(seq_along(training$CompressiveStrength),
training$CompressiveStrength,
colour = cut2(training$Age),
ylab = "Compressive strength",
xlab = "Samples")                       # TODO: how to re-label the legend?
hist(training$Superplasticizer)
hist(log(training$Superplasticizer + 1))
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData   <- data.frame(diagnosis,predictors)
inTrain  <- createDataPartition(adData$diagnosis,p=3/4)[[1]]
training <- adData[ inTrain,]
testing  <- adData[-inTrain,]
?AlzheimerDisease
?predictors
class(predictors)
names(predictors)
require(caret)
require(AppliedPredictiveModeling)
data(concrete)
set.seed(1000) # for repeatability
inTrain  <- createDataPartition(mixtures$CompressiveStrength, p=3/4)[[1]] # returns a list
training <- mixtures[inTrain,]
testing  <- mixtures[-inTrain,]
require(ggplot2)
require(Hmisc)
Cut.Cement <- cut2(training$Cement)
qplot(seq_along(training$CompressiveStrength),
training$CompressiveStrength,
colour = Cut.Cement,
ylab = "Compressive strength",
xlab = "Samples")                       # TODO: how to re-label the legend?
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData   <- data.frame(diagnosis,predictors)
inTrain  <- createDataPartition(adData$diagnosis,p=3/4)[[1]]
training <- adData[ inTrain,]
testing  <- adData[-inTrain,]
?preProcess
preProc1 <- preProcess(training[,grep("^IL", names(training))], method="pca", thresh = .9)
sum(preProc1)
summary(preProc1)
class(preProc1)
attributes(preProc1)
preProc1$method
preProc1$numComp
preProc1 <- preProcess(training[,grep("^IL", names(training))], method="pca", thresh = .8)
preProc1$numComp
preProc1 <- preProcess(training[,grep("^IL", names(training))], method="pca", thresh = .8)
preProc1$numComp # number of PCs required to capture the specified amount of variance
confusionMatrix(testing$diagnosis, predict(fitNoPCA, testing))
attributes(confusionMatrix(testing$diagnosis, predict(fitNoPCA, testing)))
summary(fitNoPCA)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData1  <- data.frame(diagnosis,predictors[, grep("^IL", names(predictors))])
inTrain  <- createDataPartition(adData$diagnosis,p=3/4)[[1]]
training <- adData[ inTrain,]
testing  <- adData[-inTrain,]
fitNoPCA <- train(diagnosis ~ ., method="glm", data=training)
confusionMatrix(testing$diagnosis, predict(fitNoPCA, testing))
summary(fitNoPCA)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData1  <- data.frame(diagnosis, predictors[, grep("^IL", names(predictors))])
inTrain  <- createDataPartition(adData$diagnosis,p=3/4)[[1]]
training <- adData[ inTrain,]
testing  <- adData[-inTrain,]
fitNoPCA <- train(diagnosis ~ ., method="glm", data=training)
confusionMatrix(testing$diagnosis, predict(fitNoPCA, testing))
savehistory("~/git-repos/R/data-science-specialization/datasci-8-practical-machine-learning/history-2016-09-06.Rhistory")
savehistory("~/git-repos/R/data-science-specialization/datasci-8-practical-machine-learning/quizzes/2016-09-06.Rhistory")
